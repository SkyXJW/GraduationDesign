import math
from collections import defaultdict

from datasets import load_dataset
import json
import re
from openai import OpenAI
from tqdm import tqdm
import time

from dataset.APPSHandler import *
from utils.utils import *
from prompt.template import *
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2,3,4,5,6,7"
os.environ["TOKENIZERS_PARALLELISM"] = "false"
from transformers import AutoTokenizer, AutoModelForCausalLM

RESULTS_FILE = "/home/xjg/GraduationDesign/results/Qwen_ablation_no_cut.json"

class Node:
    def __init__(self, state, parent=None, policy_prob=None):
        self.state = state  # å½“å‰é—®é¢˜æè¿°ã€ä»£ç ç”Ÿæˆæ€è·¯(è¢«é€‰ä¸­ç»è¿‡è¯„ä¼°é˜¶æ®µåï¼Œè¿˜ä¼šåŒ…å«ç”Ÿæˆä»£ç ä»¥åŠè¯¥ä»£ç åœ¨å…¬å…±æµ‹è¯•ç”¨ä¾‹é›†ä¸Šçš„æµ‹è¯•åé¦ˆ)
        self.parent = parent
        self.policy_prob = 0.0 if not policy_prob else policy_prob
        self.children = []
        self.visits = 0
        self.total_reward = 0.0
        self.pass_rate = 0.0  # (å…¬å…±)æµ‹è¯•ç”¨ä¾‹é€šè¿‡ç‡

class MCTS:
    def __init__(self, tokenizer, model, c_puct=1.0, alpha=1.0, a=0.8, b=0.2, v_pass=0.7, ground_truth_solution="", public_tests=[], private_tests=[], no_solutions=False, max_reward=-float('inf')):
        self.tokenizer = tokenizer
        self.model = model
        self.c_puct = c_puct
        self.alpha = alpha
        self.a = a
        self.b = b
        self.v_pass = v_pass
        self.ground_truth_solution = ground_truth_solution
        self.public_tests = public_tests
        self.private_tests = private_tests
        self.no_solutions = no_solutions
        self.max_reward = max_reward
        self.nodes = defaultdict(lambda: Node(None))
    
    def select(self, node):
        while node.children:
            # é€‰æ‹©PUCBå€¼æœ€é«˜çš„å­èŠ‚ç‚¹
            max_pucb = -float('inf')
            selected_child = None
            for child in node.children:
                if child.visits == 0: #è¿™é‡Œå¯ä»¥ç†è§£ä¸ºï¼Œå½“å‰èŠ‚ç‚¹çš„visits=0æ—¶ï¼Œå…¶å¯¹åº”çš„Q(s,a)=total_reward/visitsåˆ™æ˜¯æ— ç©·å¤§ï¼Œæ‰€ä»¥ç›´æ¥é€‰æ‹©å½“å‰èŠ‚ç‚¹
                    selected_child = child
                    break
                # if child.pass_rate < self.v_pass:
                #     continue
                q = child.total_reward / child.visits
                p = child.policy_prob
                u = self.c_puct * p * math.sqrt(math.log(node.visits)) / (1 + child.visits)
                pucb = q + u + self.alpha * compare_code_similarity(child.state["code"], self.ground_truth_solution)
                # pucb = q + u
                if pucb > max_pucb:
                    if selected_child is None:
                        max_pucb = pucb
                        selected_child = child
                    # # åœ¨childçš„pass_rateä½äºç»™å®šé˜ˆå€¼v_passçš„æƒ…å†µä¸‹ï¼Œå½“ä¸”ä»…å½“child.pass_rateæ›´é«˜æ—¶ï¼Œæ‰ä¼šè¢«é€‰ä¸­
                    # # å³æ˜¯è¯´ï¼Œè¿™æ—¶pucbçš„ä¼˜å…ˆçº§ < pass_rateçš„ä¼˜å…ˆçº§
                    # elif child.pass_rate < self.v_pass:
                    #     if child.pass_rate > selected_child.pass_rate:
                    #         max_pucb = pucb
                    #         selected_child = child
                    # # åœ¨childçš„pass_rateä¸ä½äºç»™å®šé˜ˆå€¼v_passçš„æƒ…å†µä¸‹ï¼Œå³ä½¿childçš„pass_rateå¯èƒ½ä¼šæ›´ä½ï¼Œä¹Ÿä¾ç„¶ä¼šè¢«é€‰ä¸­
                    # # å³æ˜¯è¯´ï¼Œè¿™æ—¶pucbçš„ä¼˜å…ˆçº§ > pass_rateçš„ä¼˜å…ˆçº§
                    else:
                        max_pucb = pucb
                        selected_child = child
            node = selected_child
        return node
    
    def expand(self, node, k=2):
        # è°ƒç”¨LLMç”Ÿæˆkä¸ªæ–°æ€è·¯
        new_thoughts = generate_thought(self.tokenizer, self.model, node.state["problem"], node.state["thought"], node.state["code"], node.state["feedback"], k)
        # æ·»åŠ æ–°èŠ‚ç‚¹
        for thought in new_thoughts:
            new_state = {"problem": node.state["problem"], "thought": thought["Thought"], "code": "", "feedback": ""}
            new_node = Node(new_state, parent=node, policy_prob=thought["Reasonableness"])
            node.children.append(new_node)
        # å®Œæˆæ‰©å±•åï¼Œé»˜è®¤å°†å½“å‰æ‰©å±•å¾—åˆ°çš„ç¬¬ä¸€ä¸ªå­èŠ‚ç‚¹ä½œä¸ºæœ¬æ¬¡è¢«é€‰ä¸­çš„èŠ‚ç‚¹ï¼Œç”¨äºåç»­çš„evaluateã€backpropagate
        return node.children[0]
    
    def evaluate(self, node):
        # ç”Ÿæˆä»£ç å¹¶æµ‹è¯•
        # è¿™é‡Œéœ€è¦è€ƒè™‘åˆ°ç”±äºåˆå§‹èŠ‚ç‚¹rootå¹¶ä¸åŒ…å«ä»»ä½•thoughtï¼Œå› æ­¤éœ€è¦LLM Agentç”Ÿæˆ
        #***ä½†ç»è¿‡åç»­çš„ä»£ç ä¿®æ­£ï¼Œåˆå§‹èŠ‚ç‚¹rootæ°¸è¿œä¸ä¼šè¢«é€‰ä¸­è€Œç”¨äºevaluateï¼Œæ‰€ä»¥ä¸Šè¿°è€ƒè™‘å¯ä»¥å¿½ç•¥***
        thought, code = generate_code(self.tokenizer, self.model, node.state["problem"], node.state["thought"])
        node.state["thought"] = thought
        node.state["code"] = code
        test_result = run_tests(code, self.public_tests)
        # è®¡ç®—é€šè¿‡ç‡å’ŒLLMè‡ªè¯„åˆ†æ•°
        pass_rate = test_result["pass_rate"]
        node.state["feedback"] = test_result["failed_cases"]
        if pass_rate == 1.0:
            llm_score = self_assess(self.tokenizer, self.model, node.state["problem"], code)
            reward = self.a * pass_rate + self.b * llm_score
        else:
            reward = pass_rate
        # reward = pass_rate        
        if self.no_solutions and self.max_reward <= reward:
            self.max_reward = reward
            self.ground_truth_solution = code
        return reward
    
    def backpropagate(self, node, reward):
        while node is not None:
            node.visits += 1
            node.total_reward += reward
            node = node.parent

def main():
    # åŠ è½½æ¨¡å‹
    tokenizer = AutoTokenizer.from_pretrained("/home/xjg/checkpoints/Qwen2.5-32B", trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained("/home/xjg/checkpoints/Qwen2.5-32B", device_map="auto", trust_remote_code=True)
    # åˆå§‹åŒ–MCTS
    mcts = MCTS(tokenizer, model)
    test_data = load_proceed(100) # å„ä¸ªéš¾åº¦çš„é¢˜ç›®æŠ½100é“
    first_write = False

    code = '''
def evaluate_bracket_sequence(n, tokens):
    stack = []
    current_op = '+'
    current_num = 0
    for token in tokens:
        if token == '(':
            stack.append(current_op)
            current_op = '+'
            current_num = 0
        elif token == ')':
            if current_op == '+':
                current_num = sum(stack.pop() for _ in range(len(stack)))
            else:
                current_num = reduce(lambda x, y: x * y, stack.pop() for _ in range(len(stack)))
            current_op = stack.pop()
        else:
            current_num += int(token)
    if current_op == '+':
        return sum(stack) + current_num
    else:
        return reduce(lambda x, y: x * y, stack) * current_num
n = int(input())
tokens = input().split()
result = evaluate_bracket_sequence(n, tokens)
print(result % (10**9 + 7))
'''
    failed_cases = []
    failed_cases.append({'input': '8\n1 2\n2 3\n3 4\n4 5\n4 6\n3 7\n3 8\n', 'expected_output': '5\n1 8 6', 'factual_output': '4\n5 3 1'})
    thought = '''
We can use a stack to keep track of the operations and numbers as we parse the input. When we encounter an opening parenthesis, we push the current operation onto the stack and start a new operation. When we encounter a closing parenthesis, we pop the last operation from the stack and combine it with the current operation. When we encounter a number, we add it to the current operation. Finally, we evaluate the final operation to get the result.
'''

    for category, dataset in test_data.items():
        print(f"ğŸ“‚ å¤„ç†ç±»åˆ«: {category}ï¼Œå…± {len(dataset)} é“é¢˜ç›®")

        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
        for row in tqdm(dataset, desc=f"Processing {category}"):
            if category != "competition" or row["id"] <= 3015 or row["id"] > 3029:
                continue
            # res = run_tests(code, row["private_tests"])
            # print("here")
            # print(res)
            # # è®°å½•ç»“æœ
            # result_entry = {
            #     "category": category,
            #     "question_id": row['id'],
            #     "time_taken": "Timeout",
            #     "pass_rate": res["pass_rate"],
            #     "thought": thought,
            #     "best_code": code  # ä¹Ÿå¯ä»¥å­˜å‚¨ä»£ç 
            # }
            # save_result_entry(result_entry, RESULTS_FILE, is_first=first_write)
            # exit()
            # if category == "introductory" and row["id"] > 4029:
            #     continue
            # if category == "interview" and row["id"] > 29:
            #     continue
            # if category == "competition" and row["id"] > 3029:
            #     continue
            question_id = row["id"]
            solutions_list =[""]
            if row["solutions"] != "":# ä¸ªåˆ«é¢˜ç›®æ²¡æœ‰solutions
                solutions_list = json.loads(row["solutions"])
            else:
                mcts.no_solutions = True
            # åœ¨solutionséç©ºçš„æƒ…å†µä¸‹ï¼Œå–ç¬¬ä¸€ä¸ªä½œä¸ºground_truth_solution
            # å¦åˆ™ï¼Œå°†ground_truth_solutionåˆå§‹åŒ–ä¸º""ï¼Œå¹¶åœ¨æœç´¢è¿‡ç¨‹ä¸­ï¼Œå§‹ç»ˆå°†rewardåˆ†æ•°æœ€é«˜çš„ä»£ç ä½œä¸ºground_truth_solution
            mcts.ground_truth_solution = solutions_list[0]
            mcts.public_tests = row["public_tests"]
            mcts.private_tests = row["private_tests"]

            root = Node({"problem": row["question"], "thought": "", "code": "", "feedback": ""})
            # åˆå§‹rootèŠ‚ç‚¹æ²¡æœ‰å­èŠ‚ç‚¹ï¼Œéœ€è¦å…ˆè¿›è¡Œæ‰©å±•
            mcts.expand(root)

            start_time = time.time()
            # è¿è¡Œ MCTS è¿›è¡Œä»£ç ç”Ÿæˆ
            for _ in range(10):  # è¿­ä»£æ¬¡æ•°
                leaf = mcts.select(root)
                if leaf.visits != 0:
                    leaf = mcts.expand(leaf)
                reward = mcts.evaluate(leaf)
                mcts.backpropagate(leaf, reward)
            elapsed = time.time() - start_time


            # é€‰æ‹©æœ€ä½³ä»£ç å¹¶è¯„ä¼°ç§æœ‰æµ‹è¯•é›†
            # best_code = max(root.children, key=lambda x: x.pass_rate).state["code"]
            best_node = get_best_node(root)
            best_thought = best_node.state["thought"]
            best_code = best_node.state["code"]
            private_result = run_tests(best_code, row["private_tests"])

            # è®°å½•ç»“æœ
            result_entry = {
                "category": category,
                "question_id": question_id,
                "time_taken": fmt_duration(elapsed),
                "pass_rate": private_result["pass_rate"],
                "thought": best_thought,
                "best_code": best_code
            }
            save_result_entry(result_entry, RESULTS_FILE, is_first=first_write)
            first_write = False

            print(f"âœ… {category} - {question_id} å¤„ç†å®Œæˆï¼Œç§æœ‰æµ‹è¯•é€šè¿‡ç‡: {private_result['pass_rate']:.2f}")
    finalize_results(RESULTS_FILE)
    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³", RESULTS_FILE)
if __name__ == '__main__':
    main()